# bias variance trade off
# https://www.youtube.com/watch?v=EuBBz3bI-aA&list=PLTNMv857s9WVZrO4TZ3OFmpC4bE1G5z3G&index=44
# You can add too much complexity into the model, and it will start to fit to the noise in the data rather than accurately predict the data
# This is called overfitting

# Logistic Regression Theory
# This is used for binary sets of data rather than continuous data
# It is a classification algorithm that creates a logistic curve between the two classes

# Model Evaluation
# After training a model, we need to evaluate it using a test set, called a confusion matrix
